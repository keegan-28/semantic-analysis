{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from src.cluster_labeller import Clusterer, ParamHDBSCAN\n",
    "from src.topic_modeller import vectorize_docs, embed_docs, embed_words, extract_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./datasets/News_Category_Dataset_v3.json\"\n",
    "model_path = \"./models/all-mpnet-base-v2\"\n",
    "emb_dir = \"./emb_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(data_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = [\"link\", \"authors\"]\n",
    "df.drop(columns=drop_col, inplace=True)\n",
    "df.rename(columns={\"headline\":\"message\"}, inplace=True)\n",
    "df.drop_duplicates(subset=[\"message\"], inplace=True)\n",
    "df = df[:50000]\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df[\"message\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = Clusterer(embedding_model_path=model_path, docs=docs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = clusterer.generate_emb(emb_dir=emb_dir)\n",
    "result = clusterer.load_embeddings(embeddings_dir=emb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, score, params = clusterer.cluster()\n",
    "unique, counts = np.unique(clusters, return_counts=True)\n",
    "\n",
    "# MOVE THIS TO CLASS\n",
    "print(f\"Number of docs: {len(docs)}\")\n",
    "print(f\"DBCV score: {score:.4f}\")\n",
    "print(f\"Params: {params}\")\n",
    "print(f\"Number of Classes (Not including noise): {len(unique) - 1}\")\n",
    "print(f\"Coverage: {(clusters >= 0).sum()/len(clusters)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ParamHDBSCAN(\n",
    "    min_samples=[None, 5, 6, 10],\n",
    "    min_cluster_size=[5, 10, 15],\n",
    "    cluster_selection_epsilon=[0.0, 0.1, 0.2],\n",
    "    cluster_selection_method=[\"eom\"],\n",
    "    metric=[\"euclidean\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_results = clusterer.tune_HDBSCAN(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hyperparam_tuning(tuning_results) -> None:\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'num_clusters': tuning_results[\"num_clusters\"],\n",
    "        'DBCV_score': tuning_results[\"DBCV_score\"],\n",
    "        'coverage': tuning_results[\"coverage\"],\n",
    "        'params': tuning_results[\"params\"],\n",
    "        'index': [i for i in range(len(tuning_results[\"params\"]))]\n",
    "    })\n",
    "\n",
    "    # Create the scatter plots\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add the first scatter plot\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['num_clusters'],\n",
    "        y=df['DBCV_score'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=10, color='blue'),\n",
    "        text=[f'DBCV_score: {dbcv:.4f}, Coverage: {cov*100:.2f}%, Index: {idx}' for dbcv, cov, idx in zip(df['DBCV_score'], df['coverage'], df[\"index\"])],\n",
    "        name='DBCV_score'\n",
    "    ))\n",
    "\n",
    "    # Add the second scatter plot\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['num_clusters'],\n",
    "        y=df['coverage'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=10, color='red'),\n",
    "        text=[f'DBCV_score: {dbcv:.4f}, Coverage: {cov*100:.2f}%, Index: {idx}' for dbcv, cov, idx in zip(df['DBCV_score'], df['coverage'], df[\"index\"])],\n",
    "        name='coverage'\n",
    "    ))\n",
    "\n",
    "    # Update layout to include hover mode and show the legend\n",
    "    fig.update_layout(\n",
    "        title='Num Clusters vs DBCV_score and Coverage',\n",
    "        xaxis_title='Num Clusters',\n",
    "        yaxis_title='Score/Coverage',\n",
    "        hovermode='closest'\n",
    "    )\n",
    "\n",
    "    # Add hover text to show the associated params\n",
    "    fig.update_traces(hoverinfo='text')\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hyperparam_tuning(tuning_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params: dict = tuning_results[\"params\"][16]\n",
    "# del params[\"gen_min_span_tree\"]\n",
    "\n",
    "clusters, score, params = clusterer.cluster(**params)\n",
    "unique, counts = np.unique(clusters, return_counts=True)\n",
    "counts.sort()\n",
    "\n",
    "# MOVE THIS TO CLASS\n",
    "print(f\"Number of docs: {len(docs)}\")\n",
    "print(f\"DBCV score: {score:.4f}\")\n",
    "print(f\"Params: {params}\")\n",
    "print(f\"Number of Classes (Not including noise): {len(unique) - 1}\")\n",
    "print(f\"Coverage: {(clusters >= 0).sum()/len(clusters)*100:.2f}%\")\n",
    "print(f\"Largest Cluster: {counts[-2]}\" )\n",
    "print(f\"Smallest Cluster: {params[\"min_cluster_size\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clusters\"] = clusters.astype(str)\n",
    "df[\"x\"] = result.emb_2d[:,0]\n",
    "df[\"y\"] = result.emb_2d[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_dict = {}\n",
    "\n",
    "unique_no_noise: list = unique.astype(str).tolist()\n",
    "unique_no_noise.remove('-1')\n",
    "\n",
    "for cluster in unique_no_noise:\n",
    "    try:\n",
    "        print(cluster)\n",
    "    \n",
    "        indices = df[df[\"clusters\"]==cluster].index.tolist()\n",
    "        cluster_docs = df[df[\"clusters\"]==cluster][\"message\"].to_list()    \n",
    "        words, count_matrix = vectorize_docs(cluster_docs)\n",
    "        \n",
    "        word_emb = embed_words(words, emb_model=clusterer.emb_model)\n",
    "        # doc_emb = embed_docs(cluster_docs, emb_model=clusterer.emb_model)\n",
    "        doc_emb = result.emb_source[indices]\n",
    "\n",
    "        \n",
    "        keywords = extract_keywords(cluster_docs, words, count_matrix, doc_emb, word_emb) \n",
    "        \n",
    "        keywords_dict[cluster]=keywords[\"keyword\"]\n",
    "    except ValueError as ve:\n",
    "        keywords_dict[cluster]=['']\n",
    "        print(ve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"topics\"] = df[\"clusters\"].map(keywords_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df, x='x', y='y', color='clusters', text='message')\n",
    "fig.update_traces(mode=\"markers\", hovertemplate=None)\n",
    "fig.update_layout(legend_title='Cluster')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
